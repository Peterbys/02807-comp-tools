{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+# Project 1: Customer Database\n",
    "**This is the first of three mandatory projects to be handed in as part of the assessment for the course 02807 Computational Tools for Data Science at Technical University of Denmark, autumn 2019.**\n",
    "\n",
    "#### Practical info\n",
    "- **The project is to be done in groups of at most 3 students**\n",
    "- **Each group has to hand in _one_ Jupyter notebook (this notebook) with their solution**\n",
    "- **The hand-in of the notebook is due 2019-10-13, 23:59 on DTU Inside**\n",
    "\n",
    "#### Your solution\n",
    "- **Your solution should be in Python**\n",
    "- **For each question you may use as many cells for your solution as you like**\n",
    "- **You should document your solution and explain the choices you've made (for example by using multiple cells and use Markdown to assist the reader of the notebook)**\n",
    "- **You should not remove the problem statements, and you should not modify the structure of the notebook**\n",
    "- **Your notebook should be runnable, i.e., clicking [>>] in Jupyter should generate the result that you want to be assessed**\n",
    "- **You are not expected to use machine learning to solve any of the exercises**\n",
    "- **You will be assessed according to correctness and readability of your code, choice of solution, choice of tools and libraries, and documentation of your solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Your team has been hired by the company X as data scientists. X makes gadgets for a wide range of industrial and commercial clients.\n",
    "\n",
    "As in-house data scientists, your teams first task, as per request from your new boss, is to optimize business operations. You have decided that a good first step would be to analyze the companys historical sales data to gain a better understanding of where profit is coming from. It may also reveal some low hanging fruit in terms of business opportunities.\n",
    "\n",
    "To get started, you have called the IT department to get access to the customer and sales transactions database. To your horror you've been told that such a database doens't exist, and the only record of sales transactions is kept by John from finance in an Excel spreadsheet. So you've emailed John asking for a CSV dump of the spreadsheet...\n",
    "\n",
    "In this project you need to clean the data you got from John, enrich it with further data, prepare a database for the data, and do some data analysis. The project is comprised of five parts. They are intended to be solved in the order they appear, but it is highly recommended that you read through all of them and devise an overall strategy before you start implementing anything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Cleaning the data\n",
    "John has emailed you the following link to the CSV dump you requested.\n",
    "\n",
    "- [transactions.csv](https://raw.githubusercontent.com/patrickcording/02807-comp-tools/master/docker/work/data/transactions.csv)\n",
    "\n",
    "It seems as though he has been a bit sloppy when keeping the records. \n",
    "\n",
    "In this part you should:\n",
    "- Explain what the data is\n",
    "- Clean it to prepare it for inserting into a database and doing data analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first import the packages and download the data. We only download it if we can't find it already in the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import requests\n",
    "import json\n",
    "if not os.path.exists('transactions.csv'):\n",
    "    link = 'https://raw.githubusercontent.com/patrickcording/02807-comp-tools/master/docker/work/data/transactions.csv'\n",
    "    wget.download(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then take a look at the data, first by looking at the head, and then by considering the numeber of unique values and NaN's in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         part        company         country          city     price  \\\n",
      "0  54868-5165  Chatterbridge           Spain     Barcelona   784.79€   \n",
      "1  60505-2867           Lajo          Greece  Thessaloniki   187.99€   \n",
      "2   24385-268      Flipstorm          Greece        Athens   221.73€   \n",
      "3   76117-001    Twitterbeat          France        Annecy  1075.82€   \n",
      "4  44946-1046  Chatterbridge           Spain     Barcelona   412.55€   \n",
      "5   16729-167  Chatterbridge           Spain     Barcelona   359.52€   \n",
      "6   52125-444          Voomm          France         Paris   266.62€   \n",
      "7   43419-018       Buzzbean         Germany    Düsseldorf   103.45€   \n",
      "8   54092-515          Zooxo  United Kingdom        London   £704.94   \n",
      "9  24286-1562           Lajo          Greece  Thessaloniki   317.65€   \n",
      "\n",
      "                  date  \n",
      "0  2016-01-02 00:01:05  \n",
      "1  2016-01-02 00:05:26  \n",
      "2  2016-01-02 00:18:30  \n",
      "3  2016-01-02 02:32:30  \n",
      "4  2016-01-02 04:51:55  \n",
      "5  2016-01-02 07:20:59  \n",
      "6  2016-01-02 07:40:37  \n",
      "7  2016-01-02 08:57:57  \n",
      "8  2016-01-02 09:09:01  \n",
      "9  2016-01-02 11:01:32  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('transactions.csv')\n",
    "print(data.head(n=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the base of the price is not constant, shifting from EUR to GBP, which also changes the formatting. Note that the base in this case corresponds to the country, e.g United Kingdoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values for each column:\n",
      "part         100\n",
      "company       35\n",
      "country       13\n",
      "city          30\n",
      "price      19214\n",
      "date       20552\n",
      "dtype: int64\n",
      "\n",
      "Number of NaN's for each column:\n",
      "part         10\n",
      "company       0\n",
      "country    2171\n",
      "city         33\n",
      "price         1\n",
      "date          0\n",
      "dtype: int64\n",
      "['Barcelona' 'Thessaloniki' 'Athens' 'Annecy' 'Paris' 'Düsseldorf'\n",
      " 'London' 'Braga' 'Nanterre' 'Amadora\\t' 'New York' 'Arnhem' 'Nice'\n",
      " 'Lisbon' 'Amsterdam' 'Porto' 'Boston' 'Niihama' 'Almada' 'Aranhas'\n",
      " 'Heraklion' 'Amiens' 'Patras' 'Arcueil' 'Lyon' 'Asaka' 'Champagnole'\n",
      " 'Zürich' nan 'Monção' 'Vila Fria']\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unique values for each column:\")\n",
    "print(data.nunique())\n",
    "print(\"\")\n",
    "print(\"Number of NaN's for each column:\")\n",
    "print(data.isnull().sum(axis=0))\n",
    "#print(data['city'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': {'message': 'user does not exist.', 'value': 10}}\n"
     ]
    }
   ],
   "source": [
    "payload={'q': 'Copenhagen', 'type': 'json', 'username': 'peterbysted'}\n",
    "\n",
    "r = requests.get('http://api.geonames.org/search', payload)\n",
    "\n",
    "#r.json()\n",
    "cities = json.loads(r.text)\n",
    "print(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barcelona: Spain\n",
      "Thessaloniki: Greece\n",
      "Athens: Greece\n",
      "Annecy: France\n",
      "Paris: France\n",
      "Düsseldorf: Germany\n",
      "London: United Kingdoms\n",
      "Braga: Portugal\n",
      "Nanterre: France\n",
      "Amadora\t: Portugal\n",
      "New York: USA\n",
      "Arnhem: Netherlands\n",
      "Nice: France\n",
      "Lisbon: Portugal\n",
      "Amsterdam: Netherlands\n",
      "Porto: Portugal\n",
      "Boston: USA\n",
      "Niihama: Japan\n",
      "Almada: Portugal\n",
      "Aranhas: Portugal\n",
      "Heraklion: Greece\n",
      "Amiens: France\n",
      "Patras: Greece\n",
      "Arcueil: France\n",
      "Lyon: France\n",
      "Asaka: Japan\n",
      "Champagnole: France\n",
      "Zürich: Switzerland\n",
      "nan: empty\n",
      "Monção: Portugal\n",
      "Vila Fria: Portugal\n"
     ]
    }
   ],
   "source": [
    "def city_to_country(city):\n",
    "    if str(city) == 'nan':\n",
    "        return 'empty'\n",
    "    if 'barcelona' in city.lower():\n",
    "        return 'Spain'\n",
    "    elif 'thessaloniki' in city.lower() or 'athens' in city.lower():\n",
    "        return 'Greece'\n",
    "    elif 'annecy' in city.lower() or 'paris' in city.lower() or 'nanterre' in city.lower() or 'nice' in city.lower() or \\\n",
    "    'nice' in city.lower() or 'amiens' in city.lower() or 'arcueil' in city.lower() or 'lyon' in city.lower() or \\\n",
    "    'champagnole' in city.lower():\n",
    "        return 'France'\n",
    "    elif 'thessaloniki' in city.lower() or 'athens' in city.lower() or 'heraklion' in city.lower() or 'patras' in city.lower():\n",
    "        return 'Greece'\n",
    "    elif 'braga' in city.lower() or 'amadora' in city.lower() or 'lisbon' in city.lower() or 'porto' in city.lower() \\\n",
    "    or 'almada' in city.lower() or 'aranhas' in city.lower() or 'monção' in city.lower() or 'vila fria' in city.lower():\n",
    "        return 'Portugal'\n",
    "    elif 'düsseldorf' in city.lower():\n",
    "        return 'Germany'\n",
    "    elif 'london' in city.lower():\n",
    "        return 'United Kingdoms'\n",
    "    elif 'new york' in city.lower() or 'boston' in city.lower():\n",
    "        return 'USA'\n",
    "    elif 'zürich' in city.lower():\n",
    "        return 'Switzerland'\n",
    "    elif 'amsterdam' in city.lower() or 'arnhem' in city.lower():\n",
    "        return 'Netherlands'\n",
    "    elif 'niihama' in city.lower() or 'asaka' in city.lower():\n",
    "        return 'Japan'\n",
    "for city in data['city'].unique():\n",
    "    print(str(city) + ': ' + city_to_country(city))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Enriching the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common task for a data scientists is to combine or enrich data from internal sources with data available from external sources. The purpose of this can be either to fix issues with the data or to make it easier to derive insights from the data.\n",
    "\n",
    "In this part you should enrich your data with data from at least one external source. You may look to part 4 for some  inspiration as to what is required. Your solution should be automated, i.e., you can not ask the reader of your notebook to download any data manually. You should argue why and what you expect to achieve by the enrichments you are doing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             part        company country        city      price  \\\n",
      "2528   52380-1102        Teklist     NaN      Arnhem     357.78   \n",
      "2947    52125-136    Brainsphere     NaN       Braga    493.94€   \n",
      "2956    16714-295        Teklist     NaN      Arnhem     624.4€   \n",
      "2994    76335-006       Buzzbean     NaN  Düsseldorf    355.24€   \n",
      "3948    54473-578    Brainsphere     NaN       Braga    123.32€   \n",
      "3949   54973-9150    Twitterbeat     NaN      Annecy    893.86€   \n",
      "3950   41167-0843    Brainsphere     NaN       Braga     93.93€   \n",
      "3951    51060-032       Riffpath     NaN   Heraklion    665.09€   \n",
      "3952    37205-951       Buzzbean     NaN  Düsseldorf    257.66€   \n",
      "3953    37205-951  Chatterbridge     NaN   Barcelona    181.97€   \n",
      "3954   24286-1562          Ntags     NaN      Lisbon    296.17€   \n",
      "3955    76117-001    Twitterbeat     NaN      Annecy    769.82€   \n",
      "3956    54473-578      Flipstorm     NaN      Athens    129.67€   \n",
      "3957    76454-100       Buzzbean     NaN  Düsseldorf    178.24€   \n",
      "3958    0615-7679      Flipstorm     NaN      Athens    307.67€   \n",
      "3959    49967-724     Thoughtmix     NaN   Amadora\\t    643.76€   \n",
      "3960   62011-0219     Thoughtmix     NaN   Amadora\\t    726.23€   \n",
      "3961   48951-4042    Brainsphere     NaN       Braga    189.16€   \n",
      "3962   51531-9500         Roodel     NaN     Aranhas   1013.72€   \n",
      "3963    24385-268        Wordify     NaN    New York    $147.55   \n",
      "3964    67544-356    Twitterbeat     NaN      Annecy   1258.25€   \n",
      "3965   61398-0828          Yozio     NaN      Patras    345.68€   \n",
      "3966   55154-5057         Eimbee     NaN      Amiens    506.63€   \n",
      "3967    49738-105        Wordify     NaN    New York    $623.86   \n",
      "3968    68233-011        Gabcube     NaN      Almada    128.67€   \n",
      "3969    0603-6134        Gabcube     NaN      Almada    844.56€   \n",
      "3970    58596-001       Buzzbean     NaN  Düsseldorf    464.65€   \n",
      "3971    70253-307       Riffpath     NaN   Heraklion    920.78€   \n",
      "3972    54473-578          Yozio     NaN      Patras    181.88€   \n",
      "3973   60505-2867       Buzzbean     NaN  Düsseldorf    131.15€   \n",
      "...           ...            ...     ...         ...        ...   \n",
      "12823   68462-565     Thoughtmix     NaN         NaN    777.58€   \n",
      "12824   0603-6134          Yozio     NaN         NaN    775.05€   \n",
      "12825  58118-5060          Yozio     NaN         NaN    157.53€   \n",
      "12826   51060-032     Thoughtmix     NaN         NaN    176.36€   \n",
      "12827   16714-295    Twitterbeat     NaN         NaN    348.26€   \n",
      "12828   0603-6134          Ntags     NaN         NaN    714.66€   \n",
      "12829   52125-136          Zooxo     NaN         NaN    £616.08   \n",
      "12830   70253-307     Thoughtmix     NaN         NaN    880.07€   \n",
      "12831   49967-724          Ntags     NaN         NaN     593.0€   \n",
      "12832  54868-5165        Zoonder     NaN         NaN    $879.56   \n",
      "12833  65044-3014          Zooxo     NaN         NaN    £738.09   \n",
      "12834   51346-145    Brainsphere     NaN         NaN    939.35€   \n",
      "12835  36987-1697        Wordify     NaN         NaN     $371.3   \n",
      "12836  63629-2733        Teklist     NaN         NaN    236.48€   \n",
      "12837   49035-530        Teklist     NaN         NaN   1160.47€   \n",
      "12838  62670-4404    Shufflebeat     NaN         NaN    517.91€   \n",
      "12839   0185-0373     Thoughtmix     NaN         NaN   1007.71€   \n",
      "12840   49967-724     Thoughtmix     NaN         NaN    586.71€   \n",
      "12841   59779-601          Ntags     NaN         NaN     171.8€   \n",
      "12842   35356-325    Shufflebeat     NaN         NaN    436.67€   \n",
      "12843   49349-471          Ntags     NaN         NaN   1030.42€   \n",
      "12978   98132-889        Gabcube     NaN      Almada    143.36€   \n",
      "13721   49349-314  Chatterbridge     NaN   Barcelona    499.86€   \n",
      "14438   16590-177    Shufflebeat     NaN       Porto    386.81€   \n",
      "16146   58596-001        Wordify     NaN         NaN    $492.17   \n",
      "16147   36800-952     Thoughtmix     NaN         NaN    358.03€   \n",
      "16148   51346-126       Kanoodle     NaN         NaN  ¥15949.24   \n",
      "16149   49348-574     Thoughtmix     NaN         NaN    295.01€   \n",
      "16150   0228-2167          Zooxo     NaN         NaN    £682.83   \n",
      "16151   13537-259     Thoughtmix     NaN         NaN    865.37€   \n",
      "\n",
      "                      date  \n",
      "2528   2016-04-21 04:07:31  \n",
      "2947   2016-05-10 11:13:43  \n",
      "2956   2016-05-10 21:57:15  \n",
      "2994   2016-05-12 15:17:37  \n",
      "3948   2016-07-01 01:09:40  \n",
      "3949   2016-07-01 02:59:50  \n",
      "3950   2016-07-01 04:03:16  \n",
      "3951   2016-07-01 04:56:16  \n",
      "3952   2016-07-01 06:02:32  \n",
      "3953   2016-07-01 06:26:37  \n",
      "3954   2016-07-01 06:45:57  \n",
      "3955   2016-07-01 07:09:36  \n",
      "3956   2016-07-01 07:37:53  \n",
      "3957   2016-07-01 07:40:13  \n",
      "3958   2016-07-01 08:05:28  \n",
      "3959   2016-07-01 08:31:22  \n",
      "3960   2016-07-01 12:08:25  \n",
      "3961   2016-07-01 13:48:33  \n",
      "3962   2016-07-01 15:39:42  \n",
      "3963   2016-07-01 16:13:29  \n",
      "3964   2016-07-01 19:29:53  \n",
      "3965   2016-07-01 22:16:29  \n",
      "3966   2016-07-01 23:47:21  \n",
      "3967   2016-07-02 01:08:09  \n",
      "3968   2016-07-02 02:31:40  \n",
      "3969   2016-07-02 04:37:16  \n",
      "3970   2016-07-02 06:11:48  \n",
      "3971   2016-07-02 09:53:10  \n",
      "3972   2016-07-02 10:23:02  \n",
      "3973   2016-07-02 11:32:32  \n",
      "...                    ...  \n",
      "12823  2017-10-20 21:21:18  \n",
      "12824  2017-10-20 23:17:59  \n",
      "12825  2017-10-20 23:49:53  \n",
      "12826  2017-10-21 00:11:55  \n",
      "12827  2017-10-21 01:24:52  \n",
      "12828  2017-10-21 01:53:26  \n",
      "12829  2017-10-21 04:26:42  \n",
      "12830  2017-10-21 06:19:34  \n",
      "12831  2017-10-21 08:04:12  \n",
      "12832  2017-10-21 09:35:27  \n",
      "12833  2017-10-21 10:17:08  \n",
      "12834  2017-10-21 15:06:59  \n",
      "12835  2017-10-21 15:59:29  \n",
      "12836  2017-10-21 17:14:47  \n",
      "12837  2017-10-21 22:49:57  \n",
      "12838  2017-10-22 02:54:15  \n",
      "12839  2017-10-22 04:16:08  \n",
      "12840  2017-10-22 04:34:36  \n",
      "12841  2017-10-22 05:00:42  \n",
      "12842  2017-10-22 05:10:16  \n",
      "12843  2017-10-22 07:11:01  \n",
      "12978  2017-10-29 08:07:34  \n",
      "13721  2017-12-10 18:18:06  \n",
      "14438  2018-01-20 05:04:30  \n",
      "16146  2018-04-26 08:00:25  \n",
      "16147  2018-04-26 08:16:56  \n",
      "16148  2018-04-26 16:21:00  \n",
      "16149  2018-04-26 19:16:45  \n",
      "16150  2018-04-26 22:20:00  \n",
      "16151  2018-04-26 22:34:15  \n",
      "\n",
      "[2171 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data[data['country'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   country_id  id               name  state_id\n",
      "0           1   1          Eshkashem         1\n",
      "1           1   2           Fayzabad         1\n",
      "2           1   3               Jurm         1\n",
      "3           1   4            Khandud         1\n",
      "4           1   5  Qal\\'eh-ye Panjeh         1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'country_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-f1628f772e60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcountries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://raw.githubusercontent.com/dr5hn/countries-states-cities-database/master/countries.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcities\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcities\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcities\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Copenhagen'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcountry_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'country_id' is not defined"
     ]
    }
   ],
   "source": [
    "cities = pd.read_json('https://raw.githubusercontent.com/dr5hn/countries-states-cities-database/master/cities.json')\n",
    "countries = pd.read_json('https://raw.githubusercontent.com/dr5hn/countries-states-cities-database/master/countries.json')\n",
    "\n",
    "head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     capital currency  id iso2 iso3            name phone_code\n",
      "0      Kabul      AFN   1   AF  AFG     Afghanistan         93\n",
      "1  Mariehamn      EUR   2   AX  ALA   Aland Islands    +358-18\n",
      "2     Tirana      ALL   3   AL  ALB         Albania        355\n",
      "3    Algiers      DZD   4   DZ  DZA         Algeria        213\n",
      "4  Pago Pago      USD   5   AS  ASM  American Samoa     +1-684\n",
      "    capital currency  id iso2 iso3   name phone_code\n",
      "44  Beijing      CNY  45   CN  CHN  China         86\n",
      "jeff\n"
     ]
    }
   ],
   "source": [
    "#print(countries.head())\n",
    "cph = cities[cities['name'] == 'Copenhagen']['country_id'].item()\n",
    "\n",
    "print(countries[countries['id'] == 45])\n",
    "def getCountry(city):\n",
    "        return 'jeff'\n",
    "data_cleaned = data\n",
    "for index, city in data[data['country'].isna()]['city'].iteritems():\n",
    "    data_cleaned.loc[index,'country'] = getCountry(city)\n",
    "print(data_cleaned.loc[3964,'country'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "## Part 3: Creating a database\n",
    "Storing data in a relational database has the advantages that it is persistent, fast to query, and it will be easier access for other employees at Weyland-Yutani.\n",
    "\n",
    "In this part you should:\n",
    "- Create a database and table(s) for the data\n",
    "- Insert data into the tables\n",
    "\n",
    "You may use SQLite locally to do this. You should argue why you choose to store your data the way you do. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Analyzing the data\n",
    "You are now ready to analyze the data. Your goal is to gain some actionable business insights to present to your boss. \n",
    "\n",
    "In this part, you should ask some questions and try to answer them based on the data. You should write SQL queries to retrieve the data. For each question, you should state why it is relevant and what you expect to find.\n",
    "\n",
    "To get you started, you should prepare answers to the following questions. You should add more questions.\n",
    "#### Who are the most profitable clients?\n",
    "Knowing which clients that generate the most revenue for the company will assist your boss in distributing customer service ressources.\n",
    "\n",
    "#### Are there any clients for which profit is declining?\n",
    "Declining profit from a specific client may indicate that the client is disatisfied with the product. Gaining a new client is often much more work than retaining one. Early warnings about declining profit may help your boss fighting customer churn.\n",
    "\n",
    "\n",
    "Remember, you are taking this to your new boss, so think about how you present the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Performance\n",
    "Your boss is very impressed with what you have achieved in less than two weeks, and he would like to take your idea of storing the customer and sales data in a relational database to production. However, John is concerned that the solution will not scale. His experience is telling him that you will see many occurrences of the following queries.\n",
    "\n",
    "- Show all sales to company X between time $t_1$ and time $t_2$\n",
    "- Show the latest X sales in the database\n",
    "- Show total sales per company per day\n",
    "\n",
    "Show that Johns concern is not justified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
